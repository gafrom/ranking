{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering using article embeddings\n",
    "=============\n",
    "<span style=\"color: lightsteelblue;\">Resulting embeddings are used in article recommendation task.</span>\n",
    "\n",
    "The goal of this notebook is to train a embedding space over articles from Russian online newspaper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes: 13048443\n",
      "Failures: 629\n"
     ]
    }
   ],
   "source": [
    "def read_data(folder):\n",
    "  data = collections.defaultdict(set)\n",
    "  num_lines = 0\n",
    "  num_errors = 0\n",
    "  data_files = os.listdir(folder)\n",
    "  for data_file in data_files:\n",
    "    with open(os.path.join(folder, data_file)) as f:\n",
    "      for line in f:\n",
    "        # logs are in the following format:\n",
    "        # \"/article_url 000000000114ssdfrfrf34f4r34\"\n",
    "        data_per_visit = line.rstrip().split(' ')\n",
    "\n",
    "        if len(data_per_visit) > 1:\n",
    "          num_lines += 1\n",
    "          data[data_per_visit[1]].add(data_per_visit[0])\n",
    "        else: num_errors += 1\n",
    "\n",
    "  print(f\"Successes: {num_lines}\")\n",
    "  print(f\"Failures: {num_errors}\")\n",
    "  return data, num_lines\n",
    "\n",
    "# We want to group all articles by user_ids\n",
    "# user_id => [articles_ids]\n",
    "articles_by_users, num_visits = read_data('./logs/clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build features (tokenize articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross total visited 37080 articles by a total of 5406671 unique users in 13048443 visits.\n",
      "Take only users visiting from 3 to 50 articles.\n",
      "Net total visited 10636 articles by a total of 406557 unique users.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5EAAAD2CAYAAABPywPAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmS1JkhUpIkSZLU2f8Hve5lfIozhHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168fde80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>406557.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.770283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.097511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count\n",
       "count  406557.000000\n",
       "mean        7.770283\n",
       "std         5.097511\n",
       "min         4.000000\n",
       "25%         4.000000\n",
       "50%         6.000000\n",
       "75%         9.000000\n",
       "max        49.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_NUM_USER_VISITS = 3\n",
    "MAX_NUM_USER_VISITS = 50\n",
    "\n",
    "try: all_articles\n",
    "except NameError:\n",
    "  all_articles = set(article for user_articles in articles_by_users.values() for article in user_articles)\n",
    "  array = np.array([[article, user] for user in articles_by_users for article in articles_by_users[user]])\n",
    "  articles = pd.DataFrame(array, columns = ('url', 'user_id'))\n",
    "  num_articles = len(all_articles)\n",
    "\n",
    "print(f\"Gross total visited {num_articles} articles by a total of {len(articles_by_users)} unique users in {num_visits} visits.\")\n",
    "\n",
    "visits_by_users = [[len(articles_by_users[user]), user] for user in articles_by_users if MAX_NUM_USER_VISITS > len(articles_by_users[user]) > MIN_NUM_USER_VISITS]\n",
    "visits = pd.DataFrame(np.array(visits_by_users)[:, 0].astype(int), columns = ['count'])\n",
    "\n",
    "net_articles = {article for _, user in visits_by_users for article in articles_by_users[user]}\n",
    "print(f\"Take only users visiting from {MIN_NUM_USER_VISITS} to {MAX_NUM_USER_VISITS} articles.\")\n",
    "print(f\"Net total visited {len(net_articles)} articles by a total of {len(visits_by_users)} unique users.\")\n",
    "\n",
    "# visualization\n",
    "plt.figure().set_size_inches(15, 8)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.xlabel('Number of articles visited')\n",
    "plt.ylabel('Users')\n",
    "plt.hist(visits['count'], bins = MAX_NUM_USER_VISITS - MIN_NUM_USER_VISITS - 1)\n",
    "plt.show()\n",
    "\n",
    "visits.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batches(data, batch_size, sum_size = 3):\n",
    "  for user_data in len(data):\n",
    "    if len(user_data) < sum_size * 2: continue\n",
    "  \n",
    "    indices = np.array(range(len(user_data)))\n",
    "    labels_indicies = np.random.choice(indicies, num_size, replace=False)\n",
    "    x_indicies = indicies.delete(labels_indicies)\n",
    "    \n",
    "    user_labels = user_data[label_inds]\n",
    "\n",
    "    for x in itertools.combinations(x_indicies, sum_size):\n",
    "      yield x, user_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining neural network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128 # Dimension of the embedding vector.\n",
    "window_size = 2 # How many articles to consider.\n",
    "# We pick a random validation set to sample nearest neighbors. here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. \n",
    "valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "valid_window = 100 # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.array(random.sample(range(15, valid_window), valid_size))\n",
    "num_sampled = 64 # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "  # Input data.\n",
    "  train_dataset = tf.placeholder(tf.int32, shape=[batch_size, 2 * window_size])\n",
    "  train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "  # Variables.\n",
    "  embeddings = tf.Variable(\n",
    "    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0), name='embeddings')\n",
    "  softmax_weights = tf.Variable(\n",
    "    tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                         stddev=1.0 / math.sqrt(embedding_size)))\n",
    "  softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "  # Model.\n",
    "  # Look up embeddings for inputs.\n",
    "  embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n",
    "  print(embed.shape)\n",
    "  # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases,\n",
    "                               inputs=tf.reduce_sum(embed, 1),\n",
    "                               labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n",
    "\n",
    "  # Optimizer.\n",
    "  # Note: The optimizer will optimize the softmax_weights AND the embeddings.\n",
    "  # This is because the embeddings are defined as a variable quantity and the\n",
    "  # optimizer's `minimize` method will by default modify all variable quantities \n",
    "  # that contribute to the tensor it is passed.\n",
    "  # See docs on `tf.train.Optimizer.minimize()` for more details.\n",
    "  optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
    "\n",
    "  # Compute the similarity between minibatch examples and all embeddings.\n",
    "  # We use the cosine distance:\n",
    "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "  normalized_embeddings = embeddings / norm\n",
    "  valid_embeddings = tf.nn.embedding_lookup(\n",
    "    normalized_embeddings, valid_dataset)\n",
    "  similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n",
    "\n",
    "  # Storing trained model to the disk\n",
    "  saver = tf.train.Saver([embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 150001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  average_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batch_data, batch_labels = generate_CBOW_batch(batch_size, window_size)\n",
    "    feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "    _, l, embs = session.run([optimizer, loss, embeddings], feed_dict=feed_dict)\n",
    "    average_loss += l\n",
    "\n",
    "    # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "    if step % 1000 == 0:\n",
    "      if step > 0:\n",
    "        average_loss = average_loss / 1000\n",
    "      # The average loss is an estimate of the loss over the last 1000 batches.\n",
    "      log = 'Average loss at step %d: %f' % (step, average_loss)\n",
    "      average_loss = 0\n",
    "\n",
    "      sim = similarity.eval()\n",
    "\n",
    "      clear_output(wait=True)\n",
    "      log = 'Initialized\\n' + log\n",
    "\n",
    "      for i in range(valid_size):\n",
    "        valid_word = reverse_dictionary[valid_examples[i]]\n",
    "        top_k = 8 # number of nearest neighbors\n",
    "        nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "        log = log + '\\nNearest to %s:' % valid_word\n",
    "        for k in range(top_k):\n",
    "          close_word = reverse_dictionary[nearest[k]]\n",
    "          log = '%s %s,' % (log, close_word)\n",
    "      print(log)\n",
    "  final_embeddings = normalized_embeddings.eval()\n",
    "\n",
    "  # save what have been learned\n",
    "  saver.save(session, STORAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_points = 400\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])\n",
    "\n",
    "def plot(embeddings, labels):\n",
    "  assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "  pylab.figure(figsize=(15,15))  # in inches\n",
    "  for i, label in enumerate(labels):\n",
    "    x, y = embeddings[i,:]\n",
    "    pylab.scatter(x, y)\n",
    "    pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                   ha='right', va='bottom')\n",
    "  pylab.show()\n",
    "\n",
    "words = [reverse_dictionary[i] for i in range(1, num_points+1)]\n",
    "plot(two_d_embeddings, words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
